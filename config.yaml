# 数据路径
data_path: './Data/'

# 日志级别 - 控制日志输出的详细程度
log_level: 'INFO'

# 模型配置部分（会依次运行）。请注意不能写成科学计数法的表达，必须要写成 int 或 float
models:
  # UNet 模型配置
  UNet:
    lr: 0.001                       # 学习率
    kernel_size: 3                  # 卷积核大小
    filters: [16, 32, 64]           # 网络层过滤器数量
    layers: 2                       # 每个编码器/解码器块的层数
    bn: True                        # 是否使用批归一化
    wn: True                        # 是否使用权重归一化
    wd: 0.005                       # 权重衰减(L2正则化参数)
    batch_size: 64                  # 批次大小
    epochs: 1000                    # 训练轮数(写多些没有关系，会会自动早停的)
    patience: 25                    # 早停耐心值(验证集不再改善时等待的轮数)
    save_every_n_epochs: 10         # 每N个epoch保存一次当前模型
    save_best_every_n_epochs: 10    # 每N个epoch检查并保存最佳模型
    save_dir: './checkpoints'       # 模型检查点保存目录基路径

  # UNetEx 模型配置
  UNetEx:
    lr: 0.001                       # 学习率
    kernel_size: 5                  # 卷积核大小
    filters: [8, 16, 32, 32]        # 网络层过滤器数量
    layers: 3                       # 每个编码器/解码器块的层数
    bn: False                       # 是否使用批归一化
    wn: False                       # 是否使用权重归一化
    wd: 0.005                       # 权重衰减(L2正则化参数)
    batch_size: 64                  # 批次大小
    epochs: 1000                    # 训练轮数
    patience: 25                    # 早停耐心值(验证集不再改善时等待的轮数)
    save_every_n_epochs: 10         # 每N个epoch保存一次当前模型
    save_best_every_n_epochs: 10    # 每N个epoch检查并保存最佳模型
    save_dir: './checkpoints'       # 模型检查点保存目录基路径

  # UNetExAvg 模型配置
  UNetExAvg:
    lr: 0.001                       # 学习率
    kernel_size: 3                  # 卷积核大小
    filters: [16, 32, 64]           # 网络层过滤器数量
    layers: 2                       # 每个编码器/解码器块的层数
    bn: True                        # 是否使用批归一化
    wn: True                        # 是否使用权重归一化
    wd: 0.005                       # 权重衰减(L2正则化参数)
    batch_size: 64                  # 批次大小
    epochs: 1000                    # 训练轮数
    patience: 25                    # 早停耐心值(验证集不再改善时等待的轮数)
    save_every_n_epochs: 10         # 每N个epoch保存一次当前模型
    save_best_every_n_epochs: 10    # 每N个epoch检查并保存最佳模型
    save_dir: './checkpoints'       # 模型检查点保存目录基路径

  # UNetExMod 模型配置
  UNetExMod:
    lr: 0.001                       # 学习率
    kernel_size: 3                  # 卷积核大小
    filters: [16, 32, 64]           # 网络层过滤器数量
    layers: 3                       # 每个编码器/解码器块的层数
    bn: True                        # 是否使用批归一化
    wn: True                        # 是否使用权重归一化
    wd: 0.005                       # 权重衰减(L2正则化参数)
    batch_size: 64                  # 批次大小
    epochs: 1000                    # 训练轮数
    patience: 25                    # 早停耐心值(验证集不再改善时等待的轮数)
    save_every_n_epochs: 10         # 每N个epoch保存一次当前模型
    save_best_every_n_epochs: 10    # 每N个epoch检查并保存最佳模型
    save_dir: './checkpoints'       # 模型检查点保存目录基路径

# 训练通用配置
training:
  train_ratio: 0.7              # 训练集占比(0.7表示70%用于训练，剩余30%中再划分验证集和测试集)
  resume_model_name: null       # 恢复训练的模型名称，设为null表示从头开始训练，可选值: 'UNet', 'UNetEx', 'UNetExAvg', 'UNetExMod'
  resume_path: null             # 恢复训练的检查点路径，设为null表示从头开始训练